{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE40EfFKpbYr"
      },
      "source": [
        "# Neural Machine Translation using attention mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC1czaJmwot_"
      },
      "source": [
        "##### What is Machine Translation?\n",
        "\n",
        "- Machine Translation is the task of automatically converting one natural language into another, preserving the meaning of the input text, and producing fluent text in the output language.\n",
        "\n",
        "    There are four types of machine translation:\n",
        "        - Statistical Machine Translation or SMT.\n",
        "        - Rule-based Machine Translation or RBMT.\n",
        "        - Hybrid Machine Translation or HMT.\n",
        "        - Neural Machine Translation or NMT.\n",
        "\n",
        "    In this project we have implemented Neural Machine Translation using Bahdanu Attention mechanism to translate the     English text to Telugu.\n",
        "\n",
        "##### What is NMT?\n",
        "\n",
        "- Neural machine translation, NMT for short, is the use of neural network models to learn a statistical model for machine translation.\n",
        "\n",
        "- The key benefit to the approach is that a single system can be trained directly on source and target text, no longer requiring the pipeline of specialized systems used in statistical machine learning.\n",
        "\n",
        "#### Area of Application NMT dealing with:\n",
        "- According to the graphic below, Google Translate delivers translations from Spanish, Chinese, and French to English and vice versa with different levels of accuracy on scale with human translators.\n",
        "\n",
        "![Analysis](https://github.com/pragathi1234/Machine_Translation/blob/main/images/google_analysis.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A graphic from Google Research highlighting the 2016 accuracy levels of Google Translate\n",
        "\n",
        "- Machine translation solutions are progressively being used in more areas of business, providing new applications and improved machine-learning models, as their accuracy levels rise.\n",
        "- Numerous applications evolved which where using translators now-a-days, by integrating our model to any kind of application that serves end users to understand the english text to telugu.\n",
        "- Applications involves:\n",
        "    - Agriculture.\n",
        "    - Healthcare.\n",
        "    - Finance.\n",
        "    - Software and Technology.\n",
        "    - Ecommerce.\n",
        "\n",
        "\n",
        "#### About Data:\n",
        "- We have used two datasets for modeling, data files are collected from Google Translate API and [manythings](http://www.manythings.org/anki/)\n",
        "    - The Google Translate API data consist of 2 columns and 5615 rows\n",
        "    - [Manythings](http://www.manythings.org/anki/) data consist of 2 columns and 88370 rows.\n",
        "    - Shape of final data is (93985 X 2).\n",
        "    \n",
        "#### Tasks Performed.\n",
        "- Loading the text file which contains two columns with English as source and Telugu as target.\n",
        "- Preprocessing the data until it is good fit for modeling.\n",
        "- Performed Tokenization to break the raw text into small chunks.\n",
        "- Split the data into train test for modeling and evaluation.\n",
        "- Modeling:\n",
        "    - Implemented Encoder-Decoder with Attention.\n",
        "    - Applied Predefined Hugging Face Models:\n",
        "        - facebook/mbart-large-50-one-to-many-mmt.\n",
        "        - Helsinki-NLP/opus-mt-en-dra.\n",
        "        - Helsinki-NLP/opus-mt-en-mul.\n",
        "- Evaluated all the models and compared the output with the Google translate API and retrieved the BLEU score for each model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWtJahI3pXRW"
      },
      "source": [
        "### Importing the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFLnWIorf1PH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import random\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifGZgswIpjaY"
      },
      "source": [
        "#### Reading the text file which contains English and Telugu text sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3jLPgnehhciE"
      },
      "outputs": [],
      "source": [
        "english_sentences = []\n",
        "telugu_sentences = []\n",
        "\n",
        "# Reading the text file.\n",
        "with open(\"english_telugu_data.txt\", mode='rt') as fp:\n",
        "    for line in fp.readlines():\n",
        "        eng_tel = line.split(\"++++$++++\")\n",
        "        english_sentences.append(eng_tel[0])\n",
        "        telugu_sentences.append(eng_tel[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BkjIPXEkmVB",
        "outputId": "b996bf33-93fb-420a-f3b5-a627928099fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 155798 entries, 0 to 155797\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   eng     155798 non-null  object\n",
            " 1   tel     155798 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# Displaying the information of text file.\n",
        "df1=pd.DataFrame({\"eng\":english_sentences,\"tel\":telugu_sentences})\n",
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4Gk-W4AsnOhe",
        "outputId": "0cfb3b09-6846-47d1-8fcb-206b70b368d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 eng  \\\n",
              "0                                 His legs are long.   \n",
              "1                Who taught Tom how to speak French?   \n",
              "2                       I swim in the sea every day.   \n",
              "3  Tom popped into the supermarket on his way hom...   \n",
              "4                             Smoke filled the room.   \n",
              "\n",
              "                                                 tel  \n",
              "0                     అతని కాళ్ళు పొడవుగా ఉన్నాయి.\\n  \n",
              "1          టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\\n  \n",
              "2            నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.\\n  \n",
              "3  టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడ...  \n",
              "4                              పొగ గదిని నింపింది.\\n  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2d66e1e-d0d2-4297-8b8a-3dc953323164\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>tel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>His legs are long.</td>\n",
              "      <td>అతని కాళ్ళు పొడవుగా ఉన్నాయి.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who taught Tom how to speak French?</td>\n",
              "      <td>టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swim in the sea every day.</td>\n",
              "      <td>నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tom popped into the supermarket on his way hom...</td>\n",
              "      <td>టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smoke filled the room.</td>\n",
              "      <td>పొగ గదిని నింపింది.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2d66e1e-d0d2-4297-8b8a-3dc953323164')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2d66e1e-d0d2-4297-8b8a-3dc953323164 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2d66e1e-d0d2-4297-8b8a-3dc953323164');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nokqXGV4pvO6"
      },
      "source": [
        "#### Converting the text file to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Eqn4BtFnTt4",
        "outputId": "829b9870-3e8e-4a6d-9d13-65b4c65c555f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5615 entries, 0 to 5614\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   English  5615 non-null   object\n",
            " 1   Telugu   5615 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df2=pd.read_csv(\"/content/eng_tel.csv\")\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CsTDikIin9HL",
        "outputId": "95b02682-0768-45ad-a2a9-7f10826ade63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  politicians do not have permission to do what ...   \n",
              "1         I'd like to tell you about one such child,   \n",
              "2  This percentage is even greater than the perce...   \n",
              "3  what we really mean is that they're bad at not...   \n",
              "4  .The ending portion of these Vedas is called U...   \n",
              "\n",
              "                                              Telugu  \n",
              "0  రాజకీయ నాయకులకు చేయవలసినది చేయడానికి అనుమతి లేదు.  \n",
              "1  అలాంటి ఒక పిల్లల గురించి నేను మీకు చెప్పాలనుకు...  \n",
              "2           ఈ శాతం భారతదేశంలో ఉన్న శాతం కంటే ఎక్కువ.  \n",
              "3  మేము నిజంగా అర్థం ఏమిటంటే వారు శ్రద్ధ చూపకపోవడ...  \n",
              "4        .ఈ వేదాల ముగింపు భాగాన్ని ఉపనిషత్తు అంటారు.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-655d3420-bec1-4989-a4d5-5e30738a4b93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>రాజకీయ నాయకులకు చేయవలసినది చేయడానికి అనుమతి లేదు.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>అలాంటి ఒక పిల్లల గురించి నేను మీకు చెప్పాలనుకు...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>ఈ శాతం భారతదేశంలో ఉన్న శాతం కంటే ఎక్కువ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>మేము నిజంగా అర్థం ఏమిటంటే వారు శ్రద్ధ చూపకపోవడ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>.ఈ వేదాల ముగింపు భాగాన్ని ఉపనిషత్తు అంటారు.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-655d3420-bec1-4989-a4d5-5e30738a4b93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-655d3420-bec1-4989-a4d5-5e30738a4b93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-655d3420-bec1-4989-a4d5-5e30738a4b93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df2.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Quu_EnpCpmlt"
      },
      "outputs": [],
      "source": [
        "# Renaming the columns for easy use.\n",
        "df2.rename(columns = {\"English\":\"eng\",\"Telugu\":\"tel\"},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU_7SLCzp1Vo"
      },
      "source": [
        "#### Concatenate two dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U4AAEEzoB9R",
        "outputId": "43e970c4-e3fb-424f-a50f-6321bd50e226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 161413 entries, 0 to 5614\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   eng     161413 non-null  object\n",
            " 1   tel     161413 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "new_df=pd.concat([df1, df2])\n",
        "new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "E-NoeN6xpjsG",
        "outputId": "78a096e9-ae17-49a2-9972-ca1725de195f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 eng  \\\n",
              "0                                 His legs are long.   \n",
              "1                Who taught Tom how to speak French?   \n",
              "2                       I swim in the sea every day.   \n",
              "3  Tom popped into the supermarket on his way hom...   \n",
              "4                             Smoke filled the room.   \n",
              "\n",
              "                                                 tel  \n",
              "0                     అతని కాళ్ళు పొడవుగా ఉన్నాయి.\\n  \n",
              "1          టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\\n  \n",
              "2            నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.\\n  \n",
              "3  టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడ...  \n",
              "4                              పొగ గదిని నింపింది.\\n  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b2d173d-26ae-43d2-94af-34c01675ef11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>tel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>His legs are long.</td>\n",
              "      <td>అతని కాళ్ళు పొడవుగా ఉన్నాయి.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who taught Tom how to speak French?</td>\n",
              "      <td>టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swim in the sea every day.</td>\n",
              "      <td>నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tom popped into the supermarket on his way hom...</td>\n",
              "      <td>టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్ళేటప్పుడ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smoke filled the room.</td>\n",
              "      <td>పొగ గదిని నింపింది.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b2d173d-26ae-43d2-94af-34c01675ef11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b2d173d-26ae-43d2-94af-34c01675ef11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b2d173d-26ae-43d2-94af-34c01675ef11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "new_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxTGCACrqBZv"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sNtU37Gjrfua"
      },
      "outputs": [],
      "source": [
        "exclude = set(string.punctuation) \n",
        "remove_digits = str.maketrans('', '', string.digits) \n",
        "\n",
        "# Cleaning the English text column.\n",
        "def preprocess_eng(text):\n",
        "    text = text.lower() \n",
        "    text = re.sub(\"'\", '', text) \n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.translate(remove_digits) \n",
        "    text = text.strip()\n",
        "    text = re.sub(\" +\", \" \", text) \n",
        "    text = '<start> ' + text + ' <end>'\n",
        "    return text\n",
        "\n",
        "# Cleaning the Telugu text column. \n",
        "def preprocess_tel(text):\n",
        "    text = re.sub(\"'\", '', text) \n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.strip()\n",
        "    text = re.sub(\" +\", \" \", text) \n",
        "    text = '<start> ' + text + ' <end>'\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "WR3pd3Q-sCYW",
        "outputId": "e9f05ede-3a99-433d-bb92-1327dd3a8591"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 eng  \\\n",
              "0                    <start> his legs are long <end>   \n",
              "1   <start> who taught tom how to speak french <end>   \n",
              "2          <start> i swim in the sea every day <end>   \n",
              "3  <start> tom popped into the supermarket on his...   \n",
              "4                <start> smoke filled the room <end>   \n",
              "5   <start> tom and mary understood each other <end>   \n",
              "6         <start> many men want to be thin too <end>   \n",
              "7                   <start> we need three cups <end>   \n",
              "8        <start> i warned tom not to come here <end>   \n",
              "9                    <start> you two may leave <end>   \n",
              "\n",
              "                                                 tel  \n",
              "0          <start> అతని కాళ్ళు పొడవుగా ఉన్నాయి <end>  \n",
              "1  <start> టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు...  \n",
              "2  <start> నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను <...  \n",
              "3  <start> టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్...  \n",
              "4                   <start> పొగ గదిని నింపింది <end>  \n",
              "5  <start> టామ్ మరియు మేరీ ఒకరినొకరు అర్థం చేసుకు...  \n",
              "6  <start> చాలా మంది పురుషులు కూడా సన్నగా ఉండాలని...  \n",
              "7              <start> మాకు మూడు కప్పులు అవసరం <end>  \n",
              "8  <start> టామ్‌ను ఇక్కడికి రానివ్వమని హెచ్చరించా...  \n",
              "9                 <start> మీరిద్దరూ వెళ్ళవచ్చు <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f63db42f-a66f-4522-8231-9953324250a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>tel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt; his legs are long &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; అతని కాళ్ళు పొడవుగా ఉన్నాయి &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt; who taught tom how to speak french &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; టామ్ ఫ్రెంచ్ మాట్లాడటం ఎలా నేర్పించారు...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt; i swim in the sea every day &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; నేను ప్రతి రోజు సముద్రంలో ఈత కొడతాను &lt;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt; tom popped into the supermarket on his...</td>\n",
              "      <td>&lt;start&gt; టామ్ కొంచెం పాలు కొనడానికి ఇంటికి వెళ్...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt; smoke filled the room &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; పొగ గదిని నింపింది &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;start&gt; tom and mary understood each other &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; టామ్ మరియు మేరీ ఒకరినొకరు అర్థం చేసుకు...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;start&gt; many men want to be thin too &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; చాలా మంది పురుషులు కూడా సన్నగా ఉండాలని...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;start&gt; we need three cups &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; మాకు మూడు కప్పులు అవసరం &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;start&gt; i warned tom not to come here &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; టామ్‌ను ఇక్కడికి రానివ్వమని హెచ్చరించా...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;start&gt; you two may leave &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; మీరిద్దరూ వెళ్ళవచ్చు &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f63db42f-a66f-4522-8231-9953324250a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f63db42f-a66f-4522-8231-9953324250a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f63db42f-a66f-4522-8231-9953324250a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Preprocessing the both columns by adding start and end tags for each sentences in the text file.\n",
        "new_df['eng'] = new_df['eng'].apply(preprocess_eng)\n",
        "new_df['tel'] = new_df['tel'].apply(preprocess_tel)\n",
        "new_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AnrJl8tqFn3"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jlya4Sd9sann"
      },
      "outputs": [],
      "source": [
        "# Tokenizing the text using the tensorflow module.\n",
        "def tokenize(lang):\n",
        "\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post',maxlen=20,dtype='int32')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPYRS3d9wouH"
      },
      "source": [
        "- With this `tf.keras.preprocessing.sequence.pad_sequences()` method, it transforms a list (of length num_samples) of sequences (lists of integers) into a 2D Numpy array.   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pyYmlOVLtemj"
      },
      "outputs": [],
      "source": [
        "# Applying the tokenize() function for both the columns.\n",
        "def load_dataset():\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(new_df['eng'].values)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(new_df['tel'].values)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Dwlf-VZXth_6"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset and intializing it to source and target variables as tensors.\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JGM3ElVvttS8"
      },
      "outputs": [],
      "source": [
        "# Finding the shape of source and target variables.\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntithefet84U",
        "outputId": "764f4011-4cf4-441a-c88d-1c0d11913746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137201 137201 24212 24212\n"
          ]
        }
      ],
      "source": [
        "# Using the train_test_split() function splitting the data and finding their shapes.\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.15)\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8AB3AuxVucIo"
      },
      "outputs": [],
      "source": [
        "# Initializing the buffer size, batch size, embeddings, units and epochs  \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 16\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 128\n",
        "units = 1024\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "\n",
        "vocab_inp_size =len(inp_lang.word_index.keys())\n",
        "vocab_tar_size =len(targ_lang.word_index.keys())\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y1VljiGwouI"
      },
      "source": [
        "- With the help of `tf.data.Dataset.from_tensor_slices()` method, we can get the slices of an array in the form of objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JkN_mgqNwt-G"
      },
      "outputs": [],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_inp_size+1, 300))\n",
        "for word, i in inp_lang.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGlMTzLd1XTG"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh15dFeBwouJ"
      },
      "source": [
        "#### The encoder/decoder model\n",
        "\n",
        "- The following diagram shows an overview of the model. At each time-step the decoder's output is combined with a weighted sum over the encoded input, to predict the next word. The diagram and formulas are from Luong's paper."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![English_Telugu](https://github.com/pragathi1234/Machine_Translation/blob/main/images/eng_tel.jpg)"
      ],
      "metadata": {
        "id": "OhUUL0qfA80k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-v_c0mxqJMP"
      },
      "source": [
        "#### Encoder \n",
        "- Takes a list of token IDs (from input_text_processor).\n",
        "- Looks up an embedding vector for each token (Using a layers.Embedding).\n",
        "- Processes the embeddings into a new sequence (Using a layers.GRU).\n",
        "- Returns:     \n",
        "    - The processed sequence. This will be passed to the attention head.     \n",
        "    - The internal state. This will be used to initialize the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GNKC4kxX0ixy"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"embedding_layer_encoder\",trainable=False)\n",
        "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr5dmN3_qLFK"
      },
      "source": [
        "#### Decoder with attention\n",
        "The decoder's job is to generate predictions for the next output token.\n",
        "- The decoder receives the complete encoder output.\n",
        "- It uses an RNN to keep track of what it has generated so far.\n",
        "- It uses its RNN output as the query to the attention over the encoder's output, producing the context vector.\n",
        "- It combines the RNN output and the context vector to generate the 'attention vector'.\n",
        "- It generates logit predictions for the next token based on the 'attention vector'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rEzBlaHb0jUI"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fRuD5WKo0v2_"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "encoder = Encoder(vocab_inp_size+1, 300, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size+1, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2-h2RHDl0zpc"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlMj9cmrqPgK"
      },
      "source": [
        "- The `train_step()` method, added below, handles the remaining steps except for actually running the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zgF8N5tf018Y"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    encoder.get_layer('embedding_layer_encoder').set_weights([embedding_matrix])\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Z5ar_I04LN",
        "outputId": "fd235b5c-78d8-49aa-8ced-ce882d7cd461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 3.4770\n",
            "Epoch 1 Batch 1000 Loss 1.6304\n",
            "Epoch 1 Batch 2000 Loss 1.3880\n",
            "Epoch 1 Batch 3000 Loss 1.3756\n",
            "Epoch 1 Batch 4000 Loss 1.0877\n",
            "Epoch 1 Batch 5000 Loss 0.6772\n",
            "Epoch 1 Batch 6000 Loss 1.2839\n",
            "Epoch 1 Batch 7000 Loss 1.2911\n",
            "Epoch 1 Batch 8000 Loss 0.4900\n",
            "Epoch 1 Loss 1.1557\n",
            "Time taken for 1 epoch 1112.98 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.5925\n",
            "Epoch 2 Batch 1000 Loss 0.5091\n",
            "Epoch 2 Batch 2000 Loss 0.6630\n",
            "Epoch 2 Batch 3000 Loss 0.4059\n",
            "Epoch 2 Batch 4000 Loss 0.6943\n",
            "Epoch 2 Batch 5000 Loss 0.6147\n",
            "Epoch 2 Batch 6000 Loss 0.5392\n",
            "Epoch 2 Batch 7000 Loss 0.4819\n",
            "Epoch 2 Batch 8000 Loss 0.9233\n",
            "Epoch 2 Loss 0.6053\n",
            "Time taken for 1 epoch 1086.81 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.8343\n",
            "Epoch 3 Batch 1000 Loss 0.2279\n",
            "Epoch 3 Batch 2000 Loss 0.2498\n",
            "Epoch 3 Batch 3000 Loss 0.3756\n",
            "Epoch 3 Batch 4000 Loss 0.6343\n",
            "Epoch 3 Batch 5000 Loss 0.5093\n",
            "Epoch 3 Batch 6000 Loss 0.2422\n",
            "Epoch 3 Batch 7000 Loss 0.3614\n",
            "Epoch 3 Batch 8000 Loss 0.2751\n",
            "Epoch 3 Loss 0.3850\n",
            "Time taken for 1 epoch 1086.59 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1761\n",
            "Epoch 4 Batch 1000 Loss 0.1324\n",
            "Epoch 4 Batch 2000 Loss 0.1338\n",
            "Epoch 4 Batch 3000 Loss 0.3227\n",
            "Epoch 4 Batch 4000 Loss 0.2271\n",
            "Epoch 4 Batch 5000 Loss 0.2196\n",
            "Epoch 4 Batch 6000 Loss 0.2711\n",
            "Epoch 4 Batch 7000 Loss 0.1980\n",
            "Epoch 4 Batch 8000 Loss 0.3501\n",
            "Epoch 4 Loss 0.2398\n",
            "Time taken for 1 epoch 1086.71 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1123\n",
            "Epoch 5 Batch 1000 Loss 0.4204\n",
            "Epoch 5 Batch 2000 Loss 0.2661\n",
            "Epoch 5 Batch 3000 Loss 0.2186\n",
            "Epoch 5 Batch 4000 Loss 0.2146\n",
            "Epoch 5 Batch 5000 Loss 0.4130\n",
            "Epoch 5 Batch 6000 Loss 0.1340\n",
            "Epoch 5 Batch 7000 Loss 0.1362\n",
            "Epoch 5 Batch 8000 Loss 0.1652\n",
            "Epoch 5 Loss 0.1722\n",
            "Time taken for 1 epoch 1087.05 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0616\n",
            "Epoch 6 Batch 1000 Loss 0.0865\n",
            "Epoch 6 Batch 2000 Loss 0.1584\n",
            "Epoch 6 Batch 3000 Loss 0.1283\n",
            "Epoch 6 Batch 4000 Loss 0.1228\n",
            "Epoch 6 Batch 5000 Loss 0.1402\n",
            "Epoch 6 Batch 6000 Loss 0.1252\n",
            "Epoch 6 Batch 7000 Loss 0.2200\n",
            "Epoch 6 Batch 8000 Loss 0.1687\n",
            "Epoch 6 Loss 0.1363\n",
            "Time taken for 1 epoch 1086.75 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1542\n",
            "Epoch 7 Batch 1000 Loss 0.1081\n",
            "Epoch 7 Batch 2000 Loss 0.0796\n",
            "Epoch 7 Batch 3000 Loss 0.1034\n",
            "Epoch 7 Batch 4000 Loss 0.1127\n",
            "Epoch 7 Batch 5000 Loss 0.0477\n",
            "Epoch 7 Batch 6000 Loss 0.1039\n",
            "Epoch 7 Batch 7000 Loss 0.1624\n",
            "Epoch 7 Batch 8000 Loss 0.0819\n",
            "Epoch 7 Loss 0.1117\n",
            "Time taken for 1 epoch 1087.11 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0446\n",
            "Epoch 8 Batch 1000 Loss 0.0447\n",
            "Epoch 8 Batch 2000 Loss 0.1113\n",
            "Epoch 8 Batch 3000 Loss 0.0206\n",
            "Epoch 8 Batch 4000 Loss 0.0596\n",
            "Epoch 8 Batch 5000 Loss 0.0762\n",
            "Epoch 8 Batch 6000 Loss 0.0997\n",
            "Epoch 8 Batch 7000 Loss 0.0680\n",
            "Epoch 8 Batch 8000 Loss 0.1228\n",
            "Epoch 8 Loss 0.0957\n",
            "Time taken for 1 epoch 1086.91 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0409\n",
            "Epoch 9 Batch 1000 Loss 0.0473\n",
            "Epoch 9 Batch 2000 Loss 0.0706\n",
            "Epoch 9 Batch 3000 Loss 0.0458\n",
            "Epoch 9 Batch 4000 Loss 0.0917\n",
            "Epoch 9 Batch 5000 Loss 0.0885\n",
            "Epoch 9 Batch 6000 Loss 0.0531\n",
            "Epoch 9 Batch 7000 Loss 0.0687\n",
            "Epoch 9 Batch 8000 Loss 0.0306\n",
            "Epoch 9 Loss 0.0840\n",
            "Time taken for 1 epoch 1086.94 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1039\n",
            "Epoch 10 Batch 1000 Loss 0.0822\n",
            "Epoch 10 Batch 2000 Loss 0.0356\n",
            "Epoch 10 Batch 3000 Loss 0.0867\n",
            "Epoch 10 Batch 4000 Loss 0.1376\n",
            "Epoch 10 Batch 5000 Loss 0.1002\n",
            "Epoch 10 Batch 6000 Loss 0.0615\n",
            "Epoch 10 Batch 7000 Loss 0.0634\n",
            "Epoch 10 Batch 8000 Loss 0.0798\n",
            "Epoch 10 Loss 0.0763\n",
            "Time taken for 1 epoch 1087.12 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.0701\n",
            "Epoch 11 Batch 1000 Loss 0.0452\n",
            "Epoch 11 Batch 2000 Loss 0.0720\n",
            "Epoch 11 Batch 3000 Loss 0.0601\n",
            "Epoch 11 Batch 4000 Loss 0.0548\n",
            "Epoch 11 Batch 5000 Loss 0.0630\n",
            "Epoch 11 Batch 6000 Loss 0.0497\n",
            "Epoch 11 Batch 7000 Loss 0.0597\n",
            "Epoch 11 Batch 8000 Loss 0.0851\n",
            "Epoch 11 Loss 0.0700\n",
            "Time taken for 1 epoch 1087.07 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0919\n",
            "Epoch 12 Batch 1000 Loss 0.0514\n",
            "Epoch 12 Batch 2000 Loss 0.0558\n",
            "Epoch 12 Batch 3000 Loss 0.1026\n",
            "Epoch 12 Batch 4000 Loss 0.0759\n",
            "Epoch 12 Batch 5000 Loss 0.0790\n",
            "Epoch 12 Batch 6000 Loss 0.0566\n",
            "Epoch 12 Batch 7000 Loss 0.1060\n",
            "Epoch 12 Batch 8000 Loss 0.1797\n",
            "Epoch 12 Loss 0.0658\n",
            "Time taken for 1 epoch 1087.26 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0327\n",
            "Epoch 13 Batch 1000 Loss 0.0172\n",
            "Epoch 13 Batch 2000 Loss 0.0693\n",
            "Epoch 13 Batch 3000 Loss 0.0280\n",
            "Epoch 13 Batch 4000 Loss 0.0245\n",
            "Epoch 13 Batch 5000 Loss 0.0967\n",
            "Epoch 13 Batch 6000 Loss 0.0506\n",
            "Epoch 13 Batch 7000 Loss 0.0824\n",
            "Epoch 13 Batch 8000 Loss 0.0400\n",
            "Epoch 13 Loss 0.0618\n",
            "Time taken for 1 epoch 1086.95 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0406\n",
            "Epoch 14 Batch 1000 Loss 0.0646\n",
            "Epoch 14 Batch 2000 Loss 0.0356\n",
            "Epoch 14 Batch 3000 Loss 0.0505\n",
            "Epoch 14 Batch 4000 Loss 0.0479\n",
            "Epoch 14 Batch 5000 Loss 0.0256\n",
            "Epoch 14 Batch 6000 Loss 0.0520\n",
            "Epoch 14 Batch 7000 Loss 0.0306\n",
            "Epoch 14 Batch 8000 Loss 0.0918\n",
            "Epoch 14 Loss 0.0605\n",
            "Time taken for 1 epoch 1086.88 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0836\n",
            "Epoch 15 Batch 1000 Loss 0.0482\n",
            "Epoch 15 Batch 2000 Loss 0.0557\n",
            "Epoch 15 Batch 3000 Loss 0.0945\n",
            "Epoch 15 Batch 4000 Loss 0.0513\n",
            "Epoch 15 Batch 5000 Loss 0.0510\n",
            "Epoch 15 Batch 6000 Loss 0.0540\n",
            "Epoch 15 Batch 7000 Loss 0.0450\n",
            "Epoch 15 Batch 8000 Loss 0.0786\n",
            "Epoch 15 Loss 0.0576\n",
            "Time taken for 1 epoch 1086.61 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0162\n",
            "Epoch 16 Batch 1000 Loss 0.0226\n",
            "Epoch 16 Batch 2000 Loss 0.0670\n",
            "Epoch 16 Batch 3000 Loss 0.0455\n",
            "Epoch 16 Batch 4000 Loss 0.0649\n",
            "Epoch 16 Batch 5000 Loss 0.0701\n",
            "Epoch 16 Batch 6000 Loss 0.0746\n",
            "Epoch 16 Batch 7000 Loss 0.0532\n",
            "Epoch 16 Batch 8000 Loss 0.0410\n",
            "Epoch 16 Loss 0.0561\n",
            "Time taken for 1 epoch 1086.51 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0348\n",
            "Epoch 17 Batch 1000 Loss 0.0446\n",
            "Epoch 17 Batch 2000 Loss 0.0483\n",
            "Epoch 17 Batch 3000 Loss 0.0790\n",
            "Epoch 17 Batch 4000 Loss 0.1128\n",
            "Epoch 17 Batch 5000 Loss 0.0306\n",
            "Epoch 17 Batch 6000 Loss 0.0785\n",
            "Epoch 17 Batch 7000 Loss 0.0497\n",
            "Epoch 17 Batch 8000 Loss 0.0363\n",
            "Epoch 17 Loss 0.0547\n",
            "Time taken for 1 epoch 1086.79 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0413\n",
            "Epoch 18 Batch 1000 Loss 0.0256\n",
            "Epoch 18 Batch 2000 Loss 0.0269\n",
            "Epoch 18 Batch 3000 Loss 0.0964\n",
            "Epoch 18 Batch 4000 Loss 0.0565\n",
            "Epoch 18 Batch 5000 Loss 0.0209\n",
            "Epoch 18 Batch 6000 Loss 0.1108\n",
            "Epoch 18 Batch 7000 Loss 0.0723\n",
            "Epoch 18 Batch 8000 Loss 0.0383\n",
            "Epoch 18 Loss 0.0535\n",
            "Time taken for 1 epoch 1086.80 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0881\n",
            "Epoch 19 Batch 1000 Loss 0.0311\n",
            "Epoch 19 Batch 2000 Loss 0.0435\n",
            "Epoch 19 Batch 3000 Loss 0.0348\n",
            "Epoch 19 Batch 4000 Loss 0.0823\n",
            "Epoch 19 Batch 5000 Loss 0.0288\n",
            "Epoch 19 Batch 6000 Loss 0.0849\n",
            "Epoch 19 Batch 7000 Loss 0.0698\n",
            "Epoch 19 Batch 8000 Loss 0.0168\n",
            "Epoch 19 Loss 0.0524\n",
            "Time taken for 1 epoch 1086.58 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0690\n",
            "Epoch 20 Batch 1000 Loss 0.0238\n",
            "Epoch 20 Batch 2000 Loss 0.0680\n",
            "Epoch 20 Batch 3000 Loss 0.0326\n",
            "Epoch 20 Batch 4000 Loss 0.0982\n",
            "Epoch 20 Batch 5000 Loss 0.0441\n",
            "Epoch 20 Batch 6000 Loss 0.0410\n",
            "Epoch 20 Batch 7000 Loss 0.0392\n",
            "Epoch 20 Batch 8000 Loss 0.0552\n",
            "Epoch 20 Loss 0.0519\n",
            "Time taken for 1 epoch 1086.85 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 1000 == 0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k8YxMFnqYRm"
      },
      "source": [
        "###  Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4uc2LiTC06gF"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_eng(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=20, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result,attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result,attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence= 'please ensure that you use the appropriate form '\n",
        "print('Input sentence in english : ',input_sentence)\n",
        "predicted_output_1,attention_plot=evaluate(input_sentence)\n",
        "print('Predicted sentence in telugu : ',predicted_output_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEbUYkZeyArd",
        "outputId": "5323d7fc-0f03-4fc9-f36f-ea98bfe25cc7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence in english :  please ensure that you use the appropriate form \n",
            "Predicted sentence in telugu :  మీరు అవసరమైన విధంగా దరఖాస్తు చేసుకోవాలి <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence=\"Hello my friends! How are you doing today?\"\n",
        "print('Input sentence in english : ',input_sentence)\n",
        "predicted_output_2,attention_plot=evaluate(input_sentence)\n",
        "print('Predicted sentence in telugu : ',predicted_output_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3rIcJbkyDx6",
        "outputId": "c518b81c-7c03-4098-f792-5499e519f4fb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence in english :  Hello my friends! How are you doing today?\n",
            "Predicted sentence in telugu :  ఈ రోజు మీ ఆలస్యంగా ఎలా ధన్యవాదాలు <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4RoAKpOaZSR",
        "outputId": "250d4f56-9b68-4e43-da02-3ef5112b7d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.10.8)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=8ed4ca60be6a4b6bd6b17d686e7d044a161826944839e380e3b71640b0aaeb85\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans==3.1.0a0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoadY3P2afNn",
        "outputId": "d95e62b2-190b-433b-94c3-5e64ae6b7073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "హలో నా స్నేహితులారా! ఈరోజు మీరు ఎలా ఉన్నారు?\n"
          ]
        }
      ],
      "source": [
        "from googletrans import Translator\n",
        "translator=Translator()\n",
        "out=translator.translate(\"Hello my friends! How are you doing today?\",dest=\"te\")\n",
        "print(out.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "yVDaUWkI167H"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu \n",
        "from nltk.translate.bleu_score import SmoothingFunction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5532cCP5aa3P",
        "outputId": "53156a8d-6e75-407c-bb96-868207a5d180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for encoder-decoder model with attention is:  0.7427498127683173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = out.text\n",
        "candidate = predicted_output_1\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print(\"BLEU score for encoder-decoder model with attention is: \",score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiCmkE92a6mx",
        "outputId": "e41f7d42-75ff-40ec-e996-bca3ccba5eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for encoder-decoder model with attention mechanism is:  0.7691605673134586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "reference_1 = out.text\n",
        "candidate_1 = predicted_output_2 \n",
        "score_1 = sentence_bleu(reference_1, candidate_1)\n",
        "print(\"BLEU score for encoder-decoder model with attention mechanism is: \",score_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qKPSXw5qbsk"
      },
      "source": [
        "### Machine Translation using Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMwH3rI1FgY",
        "outputId": "b6956473-8dc1-45c2-8fcd-1ad585bcd328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 46.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 82.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 91.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ef9887f160a5803f9125c6fe836a20b83cf806c0a9843bf6d86e24e43085b662\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG1h_N3Uq86O",
        "outputId": "089f0362-edae-4516-d852-900c16ce4ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kn-FaJMWq83F"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, MarianTokenizer, MarianMTModel\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f38prQ-_v0mQ"
      },
      "source": [
        "### facebook/mbart-large-50-one-to-many-mmt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJFKtRQvgdJ"
      },
      "source": [
        "\n",
        "- This [model](https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt) is a fine-tuned version of the mBART-large-50 checkpoint.\n",
        "- It has been fine-tuned for machine translation into multiple languages.\n",
        "- It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper.\n",
        "- The model can convert between English and 49 other languages. The target language id is forced as the first generated token when translating into a target language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "snzhPUZpq80O"
      },
      "outputs": [],
      "source": [
        "model_name=\"facebook/mbart-large-50-one-to-many-mmt\"\n",
        "\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_name, src_lang=\"en_XX\")\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "input = \"Hello my friends! How are you doing today?\"\n",
        "model_inputs = tokenizer(input, return_tensors=\"pt\")\n",
        "\n",
        "generated_tokens = model.generate(**model_inputs,forced_bos_token_id=tokenizer.lang_code_to_id[\"te_IN\"])\n",
        "res=tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The translated text is: {}\".format(res[0]))"
      ],
      "metadata": {
        "id": "jW6qOXv0H-6W",
        "outputId": "13d808d4-ca81-4646-84b9-b05aa35a7fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The translated text is: హలో నా స్నేహితులు!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlIzw_xHbAP7",
        "outputId": "7ce822b4-3890-4b49-9162-7f5c35b38b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for 'facebook/mbart-large-50-one-to-many-mmt' model is:  0.9218658175671758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "reference_2 = out.text\n",
        "candidate_2 = res[0]\n",
        "score_2 = sentence_bleu(reference_2, candidate_2)\n",
        "print(\"BLEU score for 'facebook/mbart-large-50-one-to-many-mmt' model is: \",score_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ghKXpN6v3k1"
      },
      "source": [
        "### Helsinki-NLP/opus-mt-en-dra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBt7j8uvvnIS"
      },
      "source": [
        "\n",
        "- The [model](https://huggingface.co/Helsinki-NLP/opus-mt-en-dra) can translate English to dravidian languages. \n",
        "- Pre-processing: normalization + SentencePiece.\n",
        "- A sentence initial language token is required in the form of >>id<< (id = valid target language ID).\n",
        "- Bleu score - 7.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "h29Xf2GFq8xN"
      },
      "outputs": [],
      "source": [
        "model_name = 'Helsinki-NLP/opus-mt-en-dra' \n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "translation_engine = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "text_to_translate = \"Hello my friends! How are you doing today?\"\n",
        "\n",
        "translated_text = translation_engine(\">>tel<<\" +text_to_translate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The translated text is: {}\".format(translated_text[0][\"generated_text\"]))"
      ],
      "metadata": {
        "id": "7D3taTJhHSMf",
        "outputId": "f901d0e0-3313-4c1c-9174-c666dfb4dded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The translated text is: హలో నా స్నేహితులు!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iszXsJ1LbBcE",
        "outputId": "d4995a52-98c7-4b82-d14d-4c89f55ccebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for 'Helsinki-NLP/opus-mt-en-dra' model is:  0.9218658175671758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "reference_3 = out.text\n",
        "candidate_3 = translated_text[0][\"generated_text\"]\n",
        "score_3 = sentence_bleu(reference_3, candidate_3)\n",
        "print(\"BLEU score for 'Helsinki-NLP/opus-mt-en-dra' model is: \",score_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWTiQqk1v5pL"
      },
      "source": [
        "### Helsinki-NLP/opus-mt-en-mul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGqhgMZsvs1A"
      },
      "source": [
        "\n",
        "- The [model](https://huggingface.co/Helsinki-NLP/opus-mt-en-mul) can translate from English to a variety of other languages.\n",
        "- Pre-processing: Normalization + SentencePiece\n",
        "- A sentence initial language token is required in the form of >>id<<\n",
        "- BLEU score - 4.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "gNneerMvq8uQ"
      },
      "outputs": [],
      "source": [
        "model_name = 'Helsinki-NLP/opus-mt-en-mul' \n",
        "\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "translation_engine = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "text_to_translate = \"Hello my friends! How are you doing today?\" \n",
        "\n",
        "translated_text = translation_engine(\">>tel<<\" +text_to_translate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The translated text is: {}\".format(translated_text[0][\"generated_text\"]))"
      ],
      "metadata": {
        "id": "hITM8GomHUeD",
        "outputId": "7f46204f-7de1-412c-a2a0-64c5f93cb64f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The translated text is: హలో నా స్నేహితులు, మీరు నేడు ఎలా చేస్తున్నారు?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxGMcgrGq8rd",
        "outputId": "e1b6a788-b535-4a12-8922-79d91324b0a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for 'Helsinki-NLP/opus-mt-en-mul model'  is:  0.7796914510717229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "reference_4 = out.text\n",
        "candidate_4 = translated_text[0][\"generated_text\"]\n",
        "score_4 = sentence_bleu(reference_4, candidate_4)\n",
        "print(\"BLEU score for 'Helsinki-NLP/opus-mt-en-mul model'  is: \",score_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results:"
      ],
      "metadata": {
        "id": "grlaxJyOAr8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models=[\"EncoderDecoder with Attention\", \"facebook/mbart-large-50-one-to-many-mmt\",\n",
        "        \"Helsinki-NLP/opus-mt-en-dra\", \"Helsinki-NLP/opus-mt-en-mul\"]\n",
        "\n",
        "scores=[score_1,score_2,score_3,score_4]\n",
        "\n",
        "results={'Models':models,'BLEU scores':scores}\n",
        "res=pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "-jQESFzasGPu"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.head()"
      ],
      "metadata": {
        "id": "xmwc_WKyIN4N",
        "outputId": "1e8200fc-2c26-4d69-d41a-6a67840e99ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Models  BLEU scores\n",
              "0            EncoderDecoder with Attention     0.769161\n",
              "1  facebook/mbart-large-50-one-to-many-mmt     0.921866\n",
              "2              Helsinki-NLP/opus-mt-en-dra     0.921866\n",
              "3              Helsinki-NLP/opus-mt-en-mul     0.779691"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2231b30e-dfe9-4eee-a8e3-ff30a6e69137\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Models</th>\n",
              "      <th>BLEU scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EncoderDecoder with Attention</td>\n",
              "      <td>0.769161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>facebook/mbart-large-50-one-to-many-mmt</td>\n",
              "      <td>0.921866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Helsinki-NLP/opus-mt-en-dra</td>\n",
              "      <td>0.921866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Helsinki-NLP/opus-mt-en-mul</td>\n",
              "      <td>0.779691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2231b30e-dfe9-4eee-a8e3-ff30a6e69137')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2231b30e-dfe9-4eee-a8e3-ff30a6e69137 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2231b30e-dfe9-4eee-a8e3-ff30a6e69137');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuD_JQPkwouS"
      },
      "source": [
        "### Conclusion:\n",
        "In this project, we propose different mechanisms for neural machine translation: the global approach that looks at all source positions at all times, and a predefined model. When compared to the Helsinki-NLP/opus-mt-en-dra and facebook/mbart-large-50-one-to-many-mmt models, the Helsinki-NLP/opus-mt-en-mul model outperformed. We put our models to the test in NMT translation tasks between English to Telugu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZnbL1nWwouS"
      },
      "source": [
        "### References:\n",
        "\n",
        "- https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "- https://arxiv.org/pdf/1508.04025.pdf\n",
        "- https://towardsdatascience.com/neural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac\n",
        "- https://emerj.com/ai-sector-overviews/machine-translation-14-current-applications-and-services/\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Machine_Translation-Final.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}